import{_ as u,S as h}from"./Section.6db70956.js";import{_ as s,o as l,c as p,r as m,a as v,w as i,b as o,d as n,e}from"./index.6cdcacac.js";const f={},_={class:"el-menu-demo title0"};function g(t,r){return l(),p("div",_,[m(t.$slots,"default")])}var w=s(f,[["render",g]]);const b={},y=e("br",null,null,-1),k=e("b",null,"around vision-centric and data-driven autonomous driving technologies",-1),x=e("p",null,[n(" The workshop also joins hands with Motional Inc to host a "),e("b",null,"nuScenes/nuPlan challenge that focuses on vision and data-centric autonomous driving problems"),n(". ")],-1),V=e("p",null," This workshop aims to investigate 1) academic exploration and 2) industry-level vision and data-centric autonomous driving systems. We hope this workshop will attract attention and discussions between stakeholders from both industry and academia. Regarding the viability of this workshop, the topic is practical and attractive. It is highly likely that researchers across academia and industry would like to attend this workshop, as it provides new insights and builds off of past workshops (as explained below). In addition, we confirmed participation from many renowned professors and industry researchers in this area, either in the form of keynote presentations or kindly offering help. We believe this workshop will be a very successful and will indeed benefit the progress of autonomous driving research significantly. ",-1),T=e("ul",null,[e("li",null,[n(" Visual perception for autonomous driving "),e("ul",null,[e("li",null,"Object detection, tracking, semantic segmentation"),e("li",null,"Mapping and localization"),e("li",null,"Monocular/stereo depth estimation"),e("li",null,"Multi-sensory fusion")])]),e("li",null,[n(" Data-driven simulation for autonomous driving "),e("ul",null,[e("li",null,"Neural rendering")])]),e("li",null,[n(" Visual representation learning for autonomous driving "),e("ul",null,[e("li",null,"Few-shot/semi-supervised/self-supervised learning"),e("li",null,"Multi-task learning")])]),e("li",null,[n(" Data-driven motion prediction and planning for autonomous driving "),e("ul",null,[e("li",null,"Multi-agent interactive prediction/planning")])]),e("li",null," Vision-centric end-to-end driving "),e("li",null," New datasets and metrics for autonomous driving "),e("li",null," Privacy concerns on visual data ")],-1);function M(t,r){const c=w,a=h,d=u;return l(),v(d,null,{default:i(()=>[o(c,null,{default:i(()=>[n(" Vision-Centric Autonomous Driving (VCAD) "),y,n(" CVPR 2023 Workshop ")]),_:1}),e("div",null,[o(a,null,{title:i(()=>[n(" Overview ")]),text:i(()=>[n(" With the commercialization of autonomous driving and assisted driving systems, the demand for high-performance, efficient, and scalable machine learning solutions is becoming more urgent than ever before. Visual perception is a key research area of self-driving that is always attracting a lot of attention since 1) visual data provides much richer information than other sensors; 2) there is an abundance of existing visual data of driving for machine learning; and 3) cameras are affordable and pervasive on vehicles as well as other robotic systems. This workshop embraces topics "),k,n(", including vision-only or sensor fusion-based perception, self- and semi-supervised visual learning, visual perception simulation, and data-driven motion prediction and planning. "),x,V]),_:1}),o(a,null,{title:i(()=>[n(" Topics that will be covered ")]),text:i(()=>[n(" The workshop is expected to center around data-centric autonomous driving, with a particular focus on vision-based methods. It will cover but not be limited to the following topics: "),T]),_:1})])]),_:1})}var S=s(b,[["render",M]]);export{S as default};
